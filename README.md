# Heatseeker

**Don't step in lava!** ðŸ”¥
Navigate from the bottom-left to the top-right based on the heat of each tile.

[Play Heatseeker!](https://heatseeker-one.vercel.app/)

Designed as an [ARC-AGI-3 Challenge](https://arcprize.org/arc-agi/3/) game to test AI/ML model reasoning skills: "Easy for Humans, Hard for AI." Game rules are a puzzle on purpose. **For humans...** turns out the game is fairly fun, even if figuring out the rules and color hints aren't. If you're just intersted in playing a game, see the rules below.

![Heatseeker game play, level win :smiley:](./docs/assets/heatseeker%20gameplay%20screen%20-%20level%20complete.png)
![Heatseeker game play, found the lava :anguished:](./docs/assets/heatseeker%20gameplay%20screen%20-%20game%20over.png)

## Computer Use Results

### ChatGPT

[ChatGPT-5 computer use achieved level 3.](./docs/computer_use/chatgpt-5.md)

### Claude

[Claude Opus 4.1 doesn't include computer use by default, and refused to help with coding it's own API](./docs/computer_use/claude4.md). When asked to generate python code for the Claude API with computer use enabled, Claude Opus 4.1 told me:

> Claude API Limitation: The Claude API (which I am) provides text generation and reasoning, not browser control or GUI interaction capabilities. There's no "computer interaction API" from Claude/Anthropic.

---

## Gameplay Rules

Navigate from bottom-left to top-right corner to complete each level.

* Use arrow keys to move, but AVOID landing on a lava square
* Colors show the lava count in bordering squares. Increasing heat (yellow, orange, red) means more lava on the next move:
* White = 0 lava nearby
* Light Yellow = 1 lava nearby
* Bright Yellow = 2 lavas nearby
* Orange = 3 lavas nearby
* Orange-Red = 4 lavas nearby
* Light Red = 5 lavas nearby
* Dark Red = 6 lavas nearby
* Purple Red = 7 lavas nearby
* Neon Pink = 8 lavas nearby

---

## Setup & Run

### Installation

```bash
npm install
```

### Development

```bash
npm start
# or
npm run dev
```

### Build for Production

```bash
npm run build
```

### Testing

#### Unit Tests (Vitest)

* **Game logic tests** - Core algorithms like heat calculation, lava generation, move validation
* **Component tests** - React UI components, user interactions, game states

```bash
# Run tests in watch mode (development)
npm test

# Run tests once (CI/CD)
npm run test:run

# Run tests with interactive UI
npm run test:ui

# Run tests with coverage report
npm run test:coverage
```

Coverage reports are generated in the `coverage/` directory and show line-by-line test coverage for all source files.

#### End-to-End Tests (Playwright)

* **Game functionality** (22 tests) - Complete user workflows, game mechanics, mobile/keyboard controls
* **Accessibility** (8 tests) - Screen reader support, keyboard navigation, color contrast, WCAG compliance
* **Performance** (8 tests) - Load times, responsiveness, memory usage, concurrent operations

```bash
# Run E2E tests
npm run test:e2e

# Run E2E tests with interactive UI
npm run test:e2e:ui

# Run E2E tests in debug mode
npm run test:e2e:debug

# View E2E test reports
npm run test:e2e:report
```

E2E tests run across multiple browsers (Chrome, Firefox, Safari) and device types (desktop, tablet, mobile).

## Responsive Breakpoints

* Base `<640px` (mobile portrait): primary target for scaling grid/cell size; covers iPhone SE/8/X and similar compact Android devices. Grid may enable internal scroll while Move controls stay anchored.
* `sm` â‰¥640px: larger phones in landscape and small tablets; maintains scaled grid while restoring horizontal control layouts.
* `md` â‰¥768px: tablets in portrait/landscape such as iPad Mini/Air; gameplay grid approaches desktop sizing.
* `lg` â‰¥1024px: laptop-width viewports; grid reaches full desktop dimensions with generous control spacing.
* `xl` â‰¥1280px: widescreen desktops/monitors; matches existing desktop layout without additional scaling.
* `2xl` â‰¥1536px: very wide monitors/TVs; no additional changes planned beyond standard Tailwind defaults.

## Leaderboard

The leaderboard is backed by the Supabase Postgres database. Supabase credentials for local and remote environments live in `.env.local`; confirm they match project secrets before running database tasks.

### Common Supabase Commands

```bash
# create a new migration under supabase/migrations/
supabase migrations new descriptive_name

# apply pending migrations to the prbase database
supabase db push

# reset the local shadow database to re-run migrations
supabase db reset

# serve an edge function locally (reads env vars from .env.local)
supabase functions serve start-session --env-file .env.local

# deploy edge functions to Supabase
supabase functions deploy start-session
supabase functions deploy update-score
supabase functions deploy leaderboard
```

Whenever you change migrations or edge functions, push the code and redeploy (`supabase db push` followed by the appropriate `supabase functions deploy ...`) so the `prbase` database and functions stay synchronized with the repository.

---

## TODO / Future Improvements

### Error Monitoring & Logging

**Current Implementation:**
- âœ… Environment-aware logger utility (`src/utils/logger.ts`)
- âœ… Vercel Analytics integrated for performance tracking
- âœ… Console logging restricted to development environment only
- âœ… Production errors are silent (no console exposure)

**Planned Migration to Sentry:**

The current logger wrapper is designed for easy migration to Sentry. When ready:

1. **Install Sentry:**
   ```bash
   npm install @sentry/react
   ```

2. **Initialize Sentry** in `src/main.tsx`:
   ```typescript
   import * as Sentry from "@sentry/react";

   Sentry.init({
     dsn: import.meta.env.VITE_SENTRY_DSN,
     environment: import.meta.env.MODE,
     enabled: import.meta.env.PROD,
     integrations: [
       Sentry.browserTracingIntegration(),
       Sentry.replayIntegration(),
     ],
     tracesSampleRate: 0.1,
     replaysSessionSampleRate: 0.1,
     replaysOnErrorSampleRate: 1.0,
   });
   ```

3. **Update Logger** (`src/utils/logger.ts`):
   ```typescript
   // Replace production branches with:
   import * as Sentry from "@sentry/react";

   error: (message: string, error?: Error | unknown, context?: LogContext): void => {
     if (import.meta.env.DEV) {
       console.error(`[Error] ${message}`, error, context);
     } else {
       Sentry.captureException(error, {
         tags: { context: context?.functionName || 'unknown' },
         extra: context
       });
     }
   }
   ```

4. **Add Environment Variable:**
   ```bash
   # .env.local
   VITE_SENTRY_DSN=your_sentry_dsn_here
   ```

**Benefits of Sentry:**
- Stack traces with source maps
- Error grouping and deduplication
- Session replay (see what user did before error)
- Performance monitoring
- Release tracking
- User context and breadcrumbs
- Free tier: 5,000 errors/month

**Why Migrate:**
- Vercel Analytics tracks performance/web vitals, not application errors
- Sentry provides comprehensive error tracking and debugging tools
- Industry standard with excellent React integration
- Essential for production debugging and monitoring

**Timeline:** Migrate when error visibility becomes critical for debugging production issues or when the free tier traffic threshold is reached.
